import asyncio
import logging
import os
import sys
import re  # –ù—É–∂–Ω–æ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ü–∏—Ñ—Ä (27b, 9b)

from aiogram import Bot, Dispatcher, F, Router
from aiogram.client.default import DefaultBotProperties
from aiogram.enums import ParseMode
from aiogram.filters import CommandStart
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup
from aiogram.fsm.storage.memory import MemoryStorage
from aiogram.types import Message, ReplyKeyboardMarkup, KeyboardButton, ReplyKeyboardRemove
import google.generativeai as genai

# --- 1. CONFIGURATION & LOGGING ---
logging.basicConfig(level=logging.INFO, stream=sys.stdout)
logger = logging.getLogger(__name__)

TOKEN = os.getenv("TOKEN")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

print("DEBUG 0. Init: Script started.", flush=True)

if not TOKEN:
    print("CRITICAL: TOKEN is missing!", flush=True)
    sys.exit(1)

if not GEMINI_API_KEY:
    print("WARNING: GEMINI_API_KEY is missing!", flush=True)
    sys.exit(1)
else:
    genai.configure(api_key=GEMINI_API_KEY)

# --- 2. DYNAMIC MODEL SELECTION (GEMMA LOGIC) ---
CURRENT_MODEL_NAME = "models/gemini-1.5-flash" # Fallback –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π

def select_best_model():
    global CURRENT_MODEL_NAME
    print("üîé Scanning available Google models...", flush=True)
    try:
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫
        all_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º: –∏—â–µ–º gemma + it (instruction tuned)
        gemma_candidates = [m for m in all_models if "gemma" in m.lower() and "it" in m.lower()]
        
        if gemma_candidates:
            # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞: –≤—ã—Ç–∞—Å–∫–∏–≤–∞–µ–º —á–∏—Å–ª–æ –ø–µ—Ä–µ–¥ 'b' (9b, 27b) –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é
            # –ü—Ä–∏–º–µ—Ä –∏–º–µ–Ω–∏: models/gemma-2-27b-it
            def get_size(name):
                match = re.search(r'(\d+)b', name.lower())
                return int(match.group(1)) if match else 0
            
            gemma_candidates.sort(key=get_size, reverse=True)
            
            CURRENT_MODEL_NAME = gemma_candidates[0]
            print(f"   üèÜ Found Powerful Gemma: {CURRENT_MODEL_NAME} (Size matters!)", flush=True)
            print(f"   ‚ÑπÔ∏è Full list sorted: {gemma_candidates}", flush=True)
        else:
            # –ï—Å–ª–∏ Gemma –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∏—â–µ–º Gemini
            print("   ‚ö†Ô∏è Gemma models not found. Looking for Gemini...", flush=True)
            gemini_models = [m for m in all_models if "gemini" in m.lower()]
            if gemini_models:
                # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ Pro, –∏–Ω–∞—á–µ Flash
                pro = next((m for m in gemini_models if "1.5-pro" in m), None)
                flash = next((m for m in gemini_models if "1.5-flash" in m), None)
                CURRENT_MODEL_NAME = pro or flash or gemini_models[0]
                print(f"   ‚ö†Ô∏è Fallback to Gemini: {CURRENT_MODEL_NAME}", flush=True)
            else:
                print("   ‚ùå No models found at all!", flush=True)

    except Exception as e:
        print(f"   ‚ùå Model Scan Failed: {e}", flush=True)

# –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–∏—Å–∫
select_best_model()

# --- 3. SYSTEM PROMPT ---
SYSTEM_PROMPT = """
You are a senior brand positioning strategist.
Your task is NOT to create marketing copy.
Your task is to identify strategic gaps, diagnose anti-positioning patterns, and propose hypotheses.

OUTPUT STRUCTURE (Russian language, Markdown):
1. **–î–∏–∞–≥–Ω–æ–∑** (Role clarity, Anti-positioning)
2. **–¢–µ—Å—Ç 10 —Å–µ–∫—É–Ω–¥** (Can it be explained simply?)
3. **–ì–∏–ø–æ—Ç–µ–∑—ã** (3 distinct strategic angles)
4. **–¢—Ä–∏–≥–≥–µ—Ä** (Why they need a consultation)
"""

# --- 4. STATES (FSM) ---
class BrandAnalysis(StatesGroup):
    waiting_for_audience = State()
    waiting_for_problem = State()
    waiting_for_current_pos = State()
    waiting_for_competitors = State()
    waiting_for_rtb = State()
    waiting_for_explanation = State()

# --- 5. HANDLERS ---
router = Router()

@router.message(CommandStart())
async def cmd_start(message: Message, state: FSMContext):
    print(f"DEBUG 1. Start: User {message.from_user.id}", flush=True)
    await state.clear()
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —é–∑–µ—Ä—É, –∫–∞–∫–æ–π –º–æ–∑–≥ —Å–µ–π—á–∞—Å –ø–æ–¥–∫–ª—é—á–µ–Ω
    model_label = CURRENT_MODEL_NAME.split('/')[-1]
    
    welcome_text = (
        f"üëã <b>–ü—Ä–∏–≤–µ—Ç! –Ø AI-—Å—Ç—Ä–∞—Ç–µ–≥.</b>\n"
        f"‚öôÔ∏è <i>–î–≤–∏–∂–æ–∫: {model_label}</i>\n\n"
        "–Ø –Ω–∞–π–¥—É –æ—à–∏–±–∫–∏ –≤ –ø–æ–∑–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏ –∏ –ø—Ä–µ–¥–ª–æ–∂—É –≥–∏–ø–æ—Ç–µ–∑—ã.\n"
        "–ü—Ä–æ–π–¥–µ–º 6 —à–∞–≥–æ–≤."
    )
    
    kb = ReplyKeyboardMarkup(
        keyboard=[[KeyboardButton(text="üöÄ –ù–∞—á–∞—Ç—å")]],
        resize_keyboard=True, one_time_keyboard=True
    )
    await message.answer(welcome_text, reply_markup=kb)

@router.message(F.text == "üöÄ –ù–∞—á–∞—Ç—å")
async def start_survey(message: Message, state: FSMContext):
    await message.answer("<b>1. –ê—É–¥–∏—Ç–æ—Ä–∏—è:</b> –ö—Ç–æ —Ç–≤–æ–π –∫–ª–∏–µ–Ω—Ç? (–ü—Å–∏—Ö–æ—Ç–∏–ø/–°–∏—Ç—É–∞—Ü–∏—è)", reply_markup=ReplyKeyboardRemove())
    await state.set_state(BrandAnalysis.waiting_for_audience)

@router.message(BrandAnalysis.waiting_for_audience)
async def step_problem(message: Message, state: FSMContext):
    await state.update_data(audience=message.text)
    await message.answer("<b>2. –ü—Ä–æ–±–ª–µ–º–∞:</b> –ß—Ç–æ —É –Ω–∏—Ö –±–æ–ª–∏—Ç –ø–µ—Ä–µ–¥ –ø–æ–∫—É–ø–∫–æ–π?")
    await state.set_state(BrandAnalysis.waiting_for_problem)

@router.message(BrandAnalysis.waiting_for_problem)
async def step_current_pos(message: Message, state: FSMContext):
    await state.update_data(problem=message.text)
    await message.answer("<b>3. –û–ø–∏—Å–∞–Ω–∏–µ:</b> –¢–≤–æ–π —Ç–µ–∫—É—â–∏–π –æ—Ñ—Ñ–µ—Ä/—à–∞–ø–∫–∞ –ø—Ä–æ—Ñ–∏–ª—è.")
    await state.set_state(BrandAnalysis.waiting_for_current_pos)

@router.message(BrandAnalysis.waiting_for_current_pos)
async def step_competitors(message: Message, state: FSMContext):
    await state.update_data(current_positioning=message.text)
    await message.answer("<b>4. –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç—ã:</b> –° –∫–µ–º —Ç–µ–±—è —Å—Ä–∞–≤–Ω–∏–≤–∞—é—Ç?")
    await state.set_state(BrandAnalysis.waiting_for_competitors)

@router.message(BrandAnalysis.waiting_for_competitors)
async def step_rtb(message: Message, state: FSMContext):
    await state.update_data(competitors=message.text)
    await message.answer("<b>5. RTB:</b> –ü–æ—á–µ–º—É —Ç–µ–±–µ –º–æ–∂–Ω–æ –≤–µ—Ä–∏—Ç—å? (–§–∞–∫—Ç—ã/–ö–µ–π—Å—ã)")
    await state.set_state(BrandAnalysis.waiting_for_rtb)

@router.message(BrandAnalysis.waiting_for_rtb)
async def step_explanation(message: Message, state: FSMContext):
    await state.update_data(reason_to_believe=message.text)
    await message.answer("<b>6. –¢–µ—Å—Ç:</b> –ö–∞–∫ –∫–ª–∏–µ–Ω—Ç –æ–±—ä—è—Å–Ω—è–µ—Ç –¥—Ä—É–≥—É, —á–µ–º —Ç—ã –∑–∞–Ω–∏–º–∞–µ—à—å—Å—è?")
    await state.set_state(BrandAnalysis.waiting_for_explanation)

@router.message(BrandAnalysis.waiting_for_explanation)
async def finish_survey(message: Message, state: FSMContext):
    await state.update_data(explanation_test=message.text)
    
    user_data = await state.get_data()
    print(f"DEBUG. Generative Step using {CURRENT_MODEL_NAME}...", flush=True)
    
    processing_msg = await message.answer(f"‚è≥ <b>–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é ({CURRENT_MODEL_NAME.split('/')[-1]})...</b>")
    
    user_input_block = (
        f"Target Audience: {user_data.get('audience')}\n"
        f"Problem Solved: {user_data.get('problem')}\n"
        f"Current Description: {user_data.get('current_positioning')}\n"
        f"Competitors: {user_data.get('competitors')}\n"
        f"Reason to Believe: {user_data.get('reason_to_believe')}\n"
        f"Customer Explanation: {user_data.get('explanation_test')}\n"
    )

    try:
        # Gemma –Ω–∞ Google API —Ç—Ä–µ–±—É–µ—Ç —á—É—Ç—å –¥—Ä—É–≥–æ–π –∫–æ–Ω—Ñ–∏–≥, –Ω–æ —ç—Ç–æ—Ç –±–∞–∑–æ–≤—ã–π –¥–æ–ª–∂–µ–Ω —Ä–∞–±–æ—Ç–∞—Ç—å.
        # System instructions –∏–Ω–æ–≥–¥–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è –≤ —è–≤–Ω–æ–º –≤–∏–¥–µ –¥–ª—è Gemma —á–µ—Ä–µ–∑ —ç—Ç–æ—Ç SDK,
        # –ø–æ—ç—Ç–æ–º—É —è –¥—É–±–ª–∏—Ä—É—é –ø—Ä–æ–º–ø—Ç –≤ —Ç–µ–ª–æ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏.
        
        full_prompt = f"{SYSTEM_PROMPT}\n\nINPUT DATA:\n{user_input_block}"
        
        model = genai.GenerativeModel(CURRENT_MODEL_NAME)
        response = await model.generate_content_async(full_prompt)
        
        await message.answer(response.text, parse_mode=ParseMode.MARKDOWN)
        
    except Exception as e:
        print(f"CRITICAL AI ERROR: {e}", flush=True)
        await message.answer("‚ö†Ô∏è –û—à–∏–±–∫–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏. –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ.")
    
    finally:
        await processing_msg.delete()
        await state.clear()

# --- 6. MAIN ---
async def main():
    bot = Bot(token=TOKEN, default=DefaultBotProperties(parse_mode=ParseMode.HTML))
    dp = Dispatcher(storage=MemoryStorage())
    dp.include_router(router)
    
    await bot.delete_webhook(drop_pending_updates=True)
    print("DEBUG. Polling started...", flush=True)
    await dp.start_polling(bot)

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        pass
