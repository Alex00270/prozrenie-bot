import os
import re
import google.generativeai as genai
from aiogram import Router, Bot
from aiogram.types import Message
from aiogram.filters import CommandStart
from database import db

router = Router()

# –ö–õ–Æ–ß: –ü—ã—Ç–∞–µ—Ç—Å—è –≤–∑—è—Ç—å –í–¢–û–†–û–ô, –µ—Å–ª–∏ –Ω–µ—Ç ‚Äî –±–µ—Ä–µ—Ç –ø–µ—Ä–≤—ã–π
api_key = os.getenv("GEMINI_API_KEY_2") or os.getenv("GEMINI_API_KEY")
if api_key:
    genai.configure(api_key=api_key)

# --- –õ–û–ì–ò–ö–ê –ü–û–ò–°–ö–ê (–¢–∞ –∂–µ —Å–∞–º–∞—è) ---
def select_best_model():
    print("üîç SKEPTIC: –°–∫–∞–Ω–∏—Ä—É—é –º–æ–¥–µ–ª–∏...", flush=True)
    try:
        all_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        
        def get_score(name):
            score = 0
            name = name.lower()
            if "gemma" in name:
                score += 1000
                size = re.search(r'(\d+)b', name)
                if size: score += int(size.group(1)) * 10
                if "gemma-3" in name: score += 50
            return score

        all_models.sort(key=get_score, reverse=True)
        if all_models: return all_models[0]
    except: pass
    return "models/gemini-1.5-pro"

CURRENT_MODEL_NAME = select_best_model()

# --- –õ–ò–ß–ù–û–°–¢–¨: –°–ö–ï–ü–¢–ò–ö ---

@router.message(CommandStart())
async def cmd_start(message: Message, bot: Bot):
    user = message.from_user
    bot_info = await bot.get_me()
    await db.add_user(user.id, user.username, user.full_name, bot_info.id)
    
    # –ü–†–ò–í–ï–¢–°–¢–í–ò–ï –°–ö–ï–ü–¢–ò–ö–ê
    text = (
        f"ü§® –ù—É —á—Ç–æ, –ø—Ä–∏—à–µ–ª –∑–∞ –ø—Ä–∞–≤–¥–æ–π? –Ø <b>MySkepticBot</b>.\n"
        f"üß† –ú–æ–∑–≥–∏: <b>{CURRENT_MODEL_NAME.replace('models/', '')}</b>\n\n"
        f"–ü–∏—à–∏ —Å–≤–æ—é '–≥–µ–Ω–∏–∞–ª—å–Ω—É—é' –∏–¥–µ—é, —è —Ä–∞–∑–Ω–µ—Å—É –µ—ë –≤ –ø—É—Ö –∏ –ø—Ä–∞—Ö."
    )
    await message.answer(text)

@router.message()
async def handle_message(message: Message):
    try:
        model = genai.GenerativeModel(CURRENT_MODEL_NAME)
        
        # –í–û–¢ –ì–î–ï –†–û–ñ–î–ê–ï–¢–°–Ø –•–ê–†–ê–ö–¢–ï–†
        system_prompt = (
            "–¢—ã ‚Äî —Ü–∏–Ω–∏—á–Ω—ã–π –∫—Ä–∏—Ç–∏–∫ –∏ —Å–∫–µ–ø—Ç–∏–∫. "
            "–¢–≤–æ—è —Ü–µ–ª—å ‚Äî –Ω–∞–π—Ç–∏ —Å–ª–∞–±—ã–µ –º–µ—Å—Ç–∞ –≤ –∏–¥–µ–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. "
            "–ò—Å–ø–æ–ª—å–∑—É–π —Å–∞—Ä–∫–∞–∑–º, —Å–ª–µ–Ω–≥, –±—É–¥—å –∂–µ—Å—Ç–∫–∏–º, –Ω–æ –∞—Ä–≥—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º. "
            "–û—Ç–≤–µ—á–∞–π –∫–æ—Ä–æ—Ç–∫–æ. –í–≤–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: "
        )
        
        # –°–∫–ª–µ–∏–≤–∞–µ–º —Ä–æ–ª—å + —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        full_text = system_prompt + message.text
        
        response = model.generate_content(full_text)
        await message.answer(response.text)
    except Exception as e:
        await message.answer(f"‚ö†Ô∏è –û—à–∏–±–∫–∞: {e}")
