import os
import re
import google.generativeai as genai
from aiogram import Router, Bot
from aiogram.types import Message
from aiogram.filters import CommandStart
from database import db

router = Router()

# –ö–õ–Æ–ß: –ü—ã—Ç–∞–µ—Ç—Å—è –≤–∑—è—Ç—å –í–¢–û–†–û–ô, –µ—Å–ª–∏ –Ω–µ—Ç ‚Äî –±–µ—Ä–µ—Ç –ø–µ—Ä–≤—ã–π
api_key = os.getenv("GEMINI_API_KEY_2") or os.getenv("GEMINI_API_KEY")
if api_key:
    genai.configure(api_key=api_key)

# --- –õ–û–ì–ò–ö–ê –ü–û–ò–°–ö–ê (–¢–∞ –∂–µ —Å–∞–º–∞—è) ---
def select_best_model():
    print("üîç SKEPTIC: –°–∫–∞–Ω–∏—Ä—É—é –º–æ–¥–µ–ª–∏...", flush=True)
    try:
        all_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        
        def get_score(name):
            score = 0
            name = name.lower()
            if "gemma" in name:
                score += 1000
                size = re.search(r'(\d+)b', name)
                if size: score += int(size.group(1)) * 10
                if "gemma-3" in name: score += 50
            return score

        all_models.sort(key=get_score, reverse=True)
        if all_models: return all_models[0]
    except: pass
    return "models/gemini-1.5-pro"

CURRENT_MODEL_NAME = select_best_model()

# --- –õ–ò–ß–ù–û–°–¢–¨: –°–ö–ï–ü–¢–ò–ö ---

@router.message(CommandStart())
async def cmd_start(message: Message, bot: Bot):
    user = message.from_user
    bot_info = await bot.get_me()
    await db.add_user(user.id, user.username, user.full_name, bot_info.id)
    
    # –ü–†–ò–í–ï–¢–°–¢–í–ò–ï –°–ö–ï–ü–¢–ò–ö–ê
    text = (
        f"ü§® –ù—É —á—Ç–æ, –ø—Ä–∏—à–µ–ª –∑–∞ –ø—Ä–∞–≤–¥–æ–π? –Ø <b>MySkepticBot</b>.\n"
        f"üß† –ú–æ–∑–≥–∏: <b>{CURRENT_MODEL_NAME.replace('models/', '')}</b>\n\n"
        f"–ü–∏—à–∏ —Å–≤–æ—é '–≥–µ–Ω–∏–∞–ª—å–Ω—É—é' –∏–¥–µ—é, —è —Ä–∞–∑–Ω–µ—Å—É –µ—ë –≤ –ø—É—Ö –∏ –ø—Ä–∞—Ö."
    )
    await message.answer(text)

@router.message()
async def handle_message(message: Message):
    try:
        model = genai.GenerativeModel(CURRENT_MODEL_NAME)
        
        # --- (–î–ª—è –°–∫–µ–ø—Ç–∏–∫–∞ –æ—Å—Ç–∞–≤—å—Ç–µ system_prompt, –¥–ª—è –ü—Ä–æ–∑—Ä–µ–Ω–∏—è —É–±–µ—Ä–∏—Ç–µ) ---
        # –ü—Ä–∏–º–µ—Ä –¥–ª—è –°–∫–µ–ø—Ç–∏–∫–∞:
        system_prompt = "–¢—ã ‚Äî —Ü–∏–Ω–∏—á–Ω—ã–π —Å–∫–µ–ø—Ç–∏–∫. –û—Ç–≤–µ—á–∞–π –∂–µ—Å—Ç–∫–æ. " 
        full_text = system_prompt + message.text
        # ------------------------------------------------------------------
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        response = model.generate_content(full_text) # –ò–ª–∏ –ø—Ä–æ—Å—Ç–æ message.text –¥–ª—è –°—Ç—Ä–∞—Ç–µ–≥–∞
        answer_text = response.text
        
        # --- –õ–ï–ö–ê–†–°–¢–í–û –û–¢ –û–®–ò–ë–ö–ò "Message too long" ---
        if len(answer_text) > 4000:
            # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –æ–≥—Ä–æ–º–Ω—ã–π, —Ä–µ–∂–µ–º –µ–≥–æ –Ω–∞ –∫—É—Å–∫–∏
            for x in range(0, len(answer_text), 4000):
                await message.answer(answer_text[x:x+4000])
        else:
            # –ï—Å–ª–∏ –≤–ª–µ–∑–∞–µ—Ç, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–∫ –æ–±—ã—á–Ω–æ
            await message.answer(answer_text)
            
    except Exception as e:
        await message.answer(f"‚ö†Ô∏è –û—à–∏–±–∫–∞: {e}")
