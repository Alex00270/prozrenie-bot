import os
import re
import google.generativeai as genai
from aiogram import Router, Bot
from aiogram.types import Message
from aiogram.filters import CommandStart
from database import db

router = Router()

# –ö–õ–Æ–ß: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –æ—Å–Ω–æ–≤–Ω–æ–π
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

# --- –õ–û–ì–ò–ö–ê –ü–û–ò–°–ö–ê (–û–¥–∏–Ω–∞–∫–æ–≤–∞—è –¥–ª—è –≤—Å–µ—Ö) ---
def select_best_model():
    print("üîç PROZRENIE: –°–∫–∞–Ω–∏—Ä—É—é –º–æ–¥–µ–ª–∏...", flush=True)
    try:
        all_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        
        def get_score(name):
            score = 0
            name = name.lower()
            if "gemma" in name:
                score += 1000
                size = re.search(r'(\d+)b', name)
                if size: score += int(size.group(1)) * 10
                if "gemma-3" in name: score += 50
            return score

        all_models.sort(key=get_score, reverse=True)
        if all_models: return all_models[0]
    except: pass
    return "models/gemini-1.5-pro"

CURRENT_MODEL_NAME = select_best_model()

# --- –õ–ò–ß–ù–û–°–¢–¨: –°–¢–†–ê–¢–ï–ì ---

@router.message(CommandStart())
async def cmd_start(message: Message, bot: Bot):
    user = message.from_user
    bot_info = await bot.get_me()
    await db.add_user(user.id, user.username, user.full_name, bot_info.id)
    
    # –ü–†–ò–í–ï–¢–°–¢–í–ò–ï –°–¢–†–ê–¢–ï–ì–ê
    text = (
        f"üëã –ü—Ä–∏–≤–µ—Ç! –Ø <b>AI-–°—Ç—Ä–∞—Ç–µ–≥</b> (–ë–æ—Ç –ü—Ä–æ–∑—Ä–µ–Ω–∏–µ).\n"
        f"üß† –ú–æ—â–Ω–æ—Å—Ç—å: <b>{CURRENT_MODEL_NAME.replace('models/', '')}</b>\n\n"
        f"–Ø –≥–æ—Ç–æ–≤ –ø–æ–º–æ—á—å —Å –∞–Ω–∞–ª–∏–∑–æ–º, –∏–¥–µ—è–º–∏ –∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π. –ü–∏—à–∏ —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å."
    )
    await message.answer(text)

@router.message()
async def handle_message(message: Message):
    try:
        model = genai.GenerativeModel(CURRENT_MODEL_NAME)
        
        # --- (–î–ª—è –°–∫–µ–ø—Ç–∏–∫–∞ –æ—Å—Ç–∞–≤—å—Ç–µ system_prompt, –¥–ª—è –ü—Ä–æ–∑—Ä–µ–Ω–∏—è —É–±–µ—Ä–∏—Ç–µ) ---
        # –ü—Ä–∏–º–µ—Ä –¥–ª—è –°–∫–µ–ø—Ç–∏–∫–∞:
        system_prompt = "–¢—ã ‚Äî —Ü–∏–Ω–∏—á–Ω—ã–π —Å–∫–µ–ø—Ç–∏–∫. –û—Ç–≤–µ—á–∞–π –∂–µ—Å—Ç–∫–æ. " 
        full_text = system_prompt + message.text
        # ------------------------------------------------------------------
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        response = model.generate_content(full_text) # –ò–ª–∏ –ø—Ä–æ—Å—Ç–æ message.text –¥–ª—è –°—Ç—Ä–∞—Ç–µ–≥–∞
        answer_text = response.text
        
        # --- –õ–ï–ö–ê–†–°–¢–í–û –û–¢ –û–®–ò–ë–ö–ò "Message too long" ---
        if len(answer_text) > 4000:
            # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –æ–≥—Ä–æ–º–Ω—ã–π, —Ä–µ–∂–µ–º –µ–≥–æ –Ω–∞ –∫—É—Å–∫–∏
            for x in range(0, len(answer_text), 4000):
                await message.answer(answer_text[x:x+4000])
        else:
            # –ï—Å–ª–∏ –≤–ª–µ–∑–∞–µ—Ç, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–∫ –æ–±—ã—á–Ω–æ
            await message.answer(answer_text)
            
    except Exception as e:
        await message.answer(f"‚ö†Ô∏è –û—à–∏–±–∫–∞: {e}")
